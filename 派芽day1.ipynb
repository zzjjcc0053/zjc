{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed0a0fcf",
      "metadata": {},
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f0a0b0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d761dfa4-d0f4-4e70-bfaf-9061108dd6e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import cookie\n",
        "import requests\n",
        "import logging\n",
        "import time\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "from typing import Optional, Dict, Any\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "# 配置日志\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "from itertools import chain\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import threading\n",
        "from sqlalchemy.exc import SQLAlchemyError\n",
        "from queue import Queue\n",
        "\n",
        "from sqlalchemy import create_engine\n",
        "import pymysql\n",
        "\n",
        "# 创建数据库连接\n",
        "engine = create_engine('mysql+pymysql://root:sktt1faker@localhost:3306/创作者中心')\n",
        "\n",
        "# 插入DataFrame\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# from ip import proxy_pool\n",
        "from ip快代理 import ProxyPool \n",
        "    \n",
        "\n",
        "api_json={\n",
        "    '创作者中心_签约关系列表_合作中':'https://creator.xiaohongshu.com/api/galaxy/sign/user/list',\n",
        "    '创作者中心_签约关系列表_已终止合作':'https://creator.xiaohongshu.com/api/galaxy/sign/list',\n",
        "    '创作者中心_签约邀请':'https://creator.xiaohongshu.com/api/galaxy/sign/apply/list',\n",
        "    \"创作者中心_机构总览\":'https://creator.xiaohongshu.com/api/galaxy/mcn/data/user_overall',\n",
        "    \"创作者中心_数据概览\":'https://creator.xiaohongshu.com/api/galaxy/mcn/data/user_statistics',\n",
        "    \"创作者中心_博主排名_涨粉能力排名\":'https://creator.xiaohongshu.com/api/galaxy/mcn/data/query_kol_rank',\n",
        "    \"创作者中心_笔记排名\":'https://creator.xiaohongshu.com/api/galaxy/mcn/data/query_note_rank',\n",
        "    \"创作者中心_达人数据_笔记概览\":\"https://creator.xiaohongshu.com/api/galaxy/mcn/data/kol/user_statistics\",\n",
        "    \"创作者中心_签约博主_达人数据\":'https://creator.xiaohongshu.com/api/galaxy/mcn/data/query_sign_kol',\n",
        "    \"创作者中心_热门话题\":'https://creator.xiaohongshu.com/api/galaxy/creator/select/topic/detail'\n",
        "    \n",
        "    }\n",
        "def xls_to_sql(table_name, df, confirm, conn=None):\n",
        "    \"\"\"将 DataFrame 写入 MySQL。\n",
        "    如果传入 conn（SQLAlchemy Connection），则使用同一个连接，\n",
        "    便于外层开启事务统一回滚；否则直接使用全局 engine。\n",
        "    \"\"\"\n",
        "    if confirm:\n",
        "        target_con = conn if conn is not None else engine\n",
        "        df.to_sql(table_name, target_con, if_exists='append', index=False)\n",
        "        logger.info(f\"数据已成功插入到表 {table_name} 中，共 {len(df)} 条记录。\")\n",
        "    else:\n",
        "        return df, \"confirm为False，未执行插入操作\"\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5ae53750",
      "metadata": {},
      "outputs": [],
      "source": [
        "# proxy_pool=ProxyPool(max_proxies=10,refresh_interval=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0cf68e36",
      "metadata": {},
      "outputs": [],
      "source": [
        "# proxy_pool.get_proxy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc295473",
      "metadata": {},
      "source": [
        "#  创作者中心"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bc5ff9e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "    # for i in range(len(cookie.czzzx_cookie_json)):\n",
        "    #     cookie_name=list(cookie.czzzx_cookie_json.keys())[i]\n",
        "    #     print(\"data_创作者中心_签约关系列表_合作中----------\"+cookie_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d538d63",
      "metadata": {},
      "source": [
        "# 创作者中心——MAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ce4cbbd-8247-4b3b-8d82-2ff0150bed24",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Any\n",
        "\n",
        "\n",
        "class czzzx_method_Set():\n",
        "    def __init__(self):\n",
        "        # 统一的 Session + 自动重试（处理 RemoteDisconnected / 连接被重置 / 临时 5xx 等）\n",
        "        self._session = requests.Session()\n",
        "        retry_strategy = Retry(\n",
        "            total=5,\n",
        "            connect=5,\n",
        "            read=5,\n",
        "            status=5,\n",
        "            backoff_factor=1,\n",
        "            status_forcelist=[429, 500, 502, 503, 504],\n",
        "            allowed_methods=[\"GET\"],\n",
        "        )\n",
        "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "        self._session.mount(\"http://\", adapter)\n",
        "        self._session.mount(\"https://\", adapter)\n",
        "\n",
        "    def _get_json_with_retry(\n",
        "        self,\n",
        "        url,\n",
        "        cookie_name,\n",
        "        params=None,\n",
        "        timeout=30,\n",
        "        verify=False,\n",
        "        max_retries=5,\n",
        "        retry_on_success_false=True,\n",
        "    ): \n",
        "        \"\"\"GET + 解析 JSON，最多重试 max_retries 次。\n",
        "\n",
        "        - 网络层异常（RemoteDisconnected 等）会重试\n",
        "        - 如果返回 success=false（系统异常）也会重试（可关闭）\n",
        "        \"\"\"\n",
        "        last_exc = None\n",
        "        for attempt in range(1, max_retries + 1):\n",
        "            try:\n",
        "                resp = self._session.get(\n",
        "                    url=url,\n",
        "                    params=params,\n",
        "                    cookies=cookie.czzzx_cookie_json[cookie_name],\n",
        "                    headers=cookie.czzzx_headers_json[cookie_name],\n",
        "                    timeout=timeout,\n",
        "                    verify=verify,\n",
        "                )\n",
        "                resp.raise_for_status()\n",
        "                resp_json = resp.json()\n",
        "\n",
        "                if not isinstance(resp_json, dict):\n",
        "                    raise ValueError(f\"响应JSON非dict: {type(resp_json)}\")\n",
        "\n",
        "                if retry_on_success_false and resp_json.get(\"success\") is False:\n",
        "                    raise RuntimeError(\n",
        "                        f\"接口返回success=false，msg={resp_json.get('msg')}, code={resp_json.get('code')}, data={resp_json.get('data')}\"\n",
        "                    )\n",
        "\n",
        "                return resp_json\n",
        "\n",
        "            except Exception as e:\n",
        "                last_exc = e\n",
        "                logger.warning(f\"GET失败 第{attempt}/{max_retries}次: {url} params={params} err={e}\")\n",
        "                if attempt < max_retries:\n",
        "                    time.sleep(min(2 ** (attempt - 1), 8))\n",
        "\n",
        "        raise RuntimeError(f\"请求连续失败{max_retries}次: {url}\") from last_exc\n",
        "\n",
        "    def get_创作者中心_签约关系列表_合作中(self,url,cookie,headers):\n",
        "        userInfo=[]\n",
        "        session=requests.Session()\n",
        "        retry_strategy = Retry(\n",
        "                total=5,  # 总重试次数\n",
        "                backoff_factor=10,  # 退避因子\n",
        "                status_forcelist=[429, 500, 502, 503, 504],  # 需要重试的HTTP状态码\n",
        "                allowed_methods=[\"GET\"]  # 允许重试的方法\n",
        "            )\n",
        "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "        session.mount(\"http://\", adapter)\n",
        "        session.mount(\"https://\", adapter)\n",
        "\n",
        "        params = {\n",
        "            'kolUserId': '',\n",
        "            'pageNum': '1',\n",
        "            'pageSize': '100',\n",
        "        }\n",
        "        try:\n",
        "            total_page=session.get(url=url,cookies=cookie,headers=headers,timeout=30,verify=False).json()\n",
        "            total=total_page['data']['total']\n",
        "            total_pages=(total//100)+1\n",
        "            logger.info(f\"签约关系列表_合作中: {total}, 签约关系列表_合作中: {total_pages}\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logger.error(f\"请求失败，错误: {e}\")\n",
        "            return None\n",
        "        \n",
        "        for page in range(1,total_pages+1):\n",
        "            params['pageNum']=str(page)\n",
        "            try:\n",
        "                response = session.get(\n",
        "                    url=url,\n",
        "                    params=params,\n",
        "                    cookies=cookie,\n",
        "                    headers=headers,\n",
        "                    timeout=30,\n",
        "                    verify=False\n",
        "                    )\n",
        "                response.raise_for_status()  # 如果响应状态码不是200，抛出异常\n",
        "                logger.info(f\"请求成功，状态码: {response.status_code}, 页码: {page}\")\n",
        "                userInfo.append(response.json()[\"data\"][\"users\"])\n",
        "                    \n",
        "            except requests.exceptions.RequestException as e:\n",
        "                logger.error(f\"请求失败，错误: {e}, 页码: {page}\")\n",
        "                return None\n",
        "        return userInfo\n",
        "    def parse_get_创作者中心_签约关系列表_合作中(self,userInfo):\n",
        "        userInfo=list(chain.from_iterable(userInfo))\n",
        "        names = list(map(lambda x: x['userName'], userInfo))\n",
        "        userId = list(map(lambda x: x['userId'], userInfo))\n",
        "        redId = list(map(lambda x: x['redId'], userInfo))\n",
        "        favLikeNum = list(map(lambda x: x['favLikeNum'], userInfo))\n",
        "        fansNum = list(map(lambda x: x['fansNum'], userInfo))\n",
        "        noteNum = list(map(lambda x: x['noteNum'], userInfo))\n",
        "        signs = list(map(lambda x: x['signs'], userInfo))\n",
        "        data=pd.DataFrame({'names':names,'userId':userId,'redId':redId,'favLikeNum':favLikeNum,'fansNum':fansNum,'noteNum':noteNum,'signs':signs})\n",
        "        return data\n",
        "    def data_创作者中心_签约关系列表_合作中(self,cookie_name):\n",
        "        get_json_data=self.get_创作者中心_签约关系列表_合作中(url=api_json['创作者中心_签约关系列表_合作中'],cookie=cookie.czzzx_cookie_json[cookie_name],headers=cookie.czzzx_headers_json[cookie_name])\n",
        "        logger.info(f\"{cookie_name} 创作者中心_签约关系列表 数据获取完成,共 {len(get_json_data)} 条数据\")\n",
        "        f_data=self.parse_get_创作者中心_签约关系列表_合作中(get_json_data)\n",
        "        博主合作业务_mcnId_list=[]\n",
        "        博主合作业务_startTime_list=[]\n",
        "        博主合作业务_endTime_list=[]\n",
        "        买手合作业务_mcnId_list=[]\n",
        "        买手合作业务_startTime_list=[]\n",
        "        买手合作业务_endTime_list=[]\n",
        "        for i in f_data[\"signs\"]:\n",
        "            if len(i)==2:\n",
        "                博主合作业务_mcnId=i[0]['mcnUserId']\n",
        "                博主合作业务_startTime=i[0]['startTime']\n",
        "                博主合作业务_endTime=i[0]['endTime']\n",
        "                买手合作业务_mcnId=i[1]['mcnUserId']\n",
        "                买手合作业务_startTime=i[1]['startTime']\n",
        "                买手合作业务_endTime=i[1]['endTime']\n",
        "\n",
        "                博主合作业务_mcnId_list.append(博主合作业务_mcnId)\n",
        "                博主合作业务_startTime_list.append(博主合作业务_startTime)\n",
        "                博主合作业务_endTime_list.append(博主合作业务_endTime)\n",
        "                买手合作业务_mcnId_list.append(买手合作业务_mcnId)\n",
        "                买手合作业务_startTime_list.append(买手合作业务_startTime)\n",
        "                买手合作业务_endTime_list.append(买手合作业务_endTime)\n",
        "            else:\n",
        "                if i[0][\"businessType\"]==1:\n",
        "                    博主合作业务_mcnId=i[0]['mcnUserId']\n",
        "                    博主合作业务_startTime=i[0]['startTime']\n",
        "                    博主合作业务_endTime=i[0]['endTime']\n",
        "                    买手合作业务_mcnId=0\n",
        "                    买手合作业务_startTime=0\n",
        "                    买手合作业务_endTime=0\n",
        "                    博主合作业务_mcnId_list.append(博主合作业务_mcnId)\n",
        "                    博主合作业务_startTime_list.append(博主合作业务_startTime)\n",
        "                    博主合作业务_endTime_list.append(博主合作业务_endTime)\n",
        "                    买手合作业务_mcnId_list.append(买手合作业务_mcnId)\n",
        "                    买手合作业务_startTime_list.append(买手合作业务_startTime)\n",
        "                    买手合作业务_endTime_list.append(买手合作业务_endTime)\n",
        "\n",
        "                if i[0][\"businessType\"]==2:\n",
        "                    买手合作业务_mcnId=i[0]['mcnUserId']\n",
        "                    买手合作业务_startTime=i[0]['startTime']\n",
        "                    买手合作业务_endTime=i[0]['endTime']\n",
        "                    博主合作业务_mcnId=0\n",
        "                    博主合作业务_startTime=0\n",
        "                    博主合作业务_endTime=0\n",
        "                    博主合作业务_mcnId_list.append(博主合作业务_mcnId)\n",
        "                    博主合作业务_startTime_list.append(博主合作业务_startTime)\n",
        "                    博主合作业务_endTime_list.append(博主合作业务_endTime)\n",
        "                    买手合作业务_mcnId_list.append(买手合作业务_mcnId)\n",
        "                    买手合作业务_startTime_list.append(买手合作业务_startTime)\n",
        "                    买手合作业务_endTime_list.append(买手合作业务_endTime)\n",
        "        f_data[\"博主合作业务_mcnId\"]=博主合作业务_mcnId_list\n",
        "        f_data[\"博主合作业务_startTime\"]=博主合作业务_startTime_list\n",
        "        f_data[\"博主合作业务_endTime\"]=博主合作业务_endTime_list\n",
        "        f_data[\"买手合作业务_mcnId\"]=买手合作业务_mcnId_list\n",
        "        f_data[\"买手合作业务_startTime\"]=买手合作业务_startTime_list\n",
        "        f_data[\"买手合作业务_endTime\"]=买手合作业务_endTime_list            \n",
        "        \n",
        "\n",
        "\n",
        "        f_data.columns=[\"用户昵称\",'用户ID','小红书ID','获赞数','粉丝数','笔记数','签约关系','博主合作业务_mcnId','博主合作业务_startTime','博主合作业务_endTime','买手合作业务_mcnId','买手合作业务_startTime','买手合作业务_endTime']\n",
        "        f_data[\"博主合作业务_startTime\"] = f_data[\"博主合作业务_startTime\"].apply(lambda x: pd.to_datetime(x, unit='ms')+pd.Timedelta(hours=8) if x != 0 else 0)\n",
        "        f_data[\"博主合作业务_endTime\"] = f_data[\"博主合作业务_endTime\"].apply(lambda x: pd.to_datetime(x, unit='ms')+pd.Timedelta(hours=8) if x != 0 else 0)\n",
        "        f_data[\"买手合作业务_startTime\"] = f_data[\"买手合作业务_startTime\"].apply(lambda x: pd.to_datetime(x, unit='ms')+pd.Timedelta(hours=8) if x != 0 else 0)\n",
        "        f_data[\"买手合作业务_endTime\"] = f_data[\"买手合作业务_endTime\"].apply(lambda x: pd.to_datetime(x, unit='ms')+pd.Timedelta(hours=8) if x != 0 else 0)\n",
        "        f_data[\"抓取时间\"]=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        f_data[\"签约关系\"]=f_data[\"签约关系\"].astype(str)\n",
        "        f_data[\"博主合作业务_mcnId\"]=f_data[\"博主合作业务_mcnId\"].map(cookie.mcnUserId)\n",
        "        f_data[\"买手合作业务_mcnId\"]=f_data[\"买手合作业务_mcnId\"].map(cookie.mcnUserId)\n",
        "        f_data[\"抓取时间\"]=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        return f_data\n",
        "    \n",
        "\n",
        "\n",
        "    def get_创作者中心_签约关系列表_已终止合作(self,url,cookie,headers):\n",
        "        userInfo=[]\n",
        "        session=requests.Session()\n",
        "        retry_strategy = Retry(\n",
        "                total=5,  # 总重试次数\n",
        "                backoff_factor=10,  # 退避因子\n",
        "                status_forcelist=[429, 500, 502, 503, 504],  # 需要重试的HTTP状态码\n",
        "                allowed_methods=[\"GET\"]  # 允许重试的方法\n",
        "            )\n",
        "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "        session.mount(\"http://\", adapter)\n",
        "        session.mount(\"https://\", adapter)\n",
        "\n",
        "        params = {\n",
        "            'kolUserId': '',\n",
        "            'pageNum': '1',\n",
        "            'pageSize': '100',\n",
        "        }\n",
        "        try:\n",
        "            total_page=session.get(url=url,cookies=cookie,headers=headers,timeout=30,verify=False).json()\n",
        "            total=total_page['data']['total']\n",
        "            total_pages=(total//100)+1\n",
        "            logger.info(f\"签约关系列表_已终止合作: {total}, 签约关系列表_已终止合作: {total_pages}\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logger.error(f\"请求失败，错误: {e}\")\n",
        "            return None\n",
        "        \n",
        "        for page in range(1,total_pages+1):\n",
        "            params['pageNum']=str(page)\n",
        "            try:\n",
        "                response = session.get(\n",
        "                    url=url,\n",
        "                    params=params,\n",
        "                    cookies=cookie,\n",
        "                    headers=headers,\n",
        "                    timeout=30,\n",
        "                    verify=False\n",
        "                    )\n",
        "                response.raise_for_status()  # 如果响应状态码不是200，抛出异常\n",
        "                logger.info(f\"请求成功，状态码: {response.status_code}, 页码: {page}\")\n",
        "                userInfo.append(response.json()[\"data\"][\"signs\"])\n",
        "                    \n",
        "            except requests.exceptions.RequestException as e:\n",
        "                logger.error(f\"请求失败，错误: {e}, 页码: {page}\")\n",
        "                return None\n",
        "        return userInfo\n",
        "    def parse_get_创作者中心_签约关系列表_已终止合作(self,userInfo):\n",
        "        userInfo=list(chain.from_iterable(userInfo))\n",
        "        names = list(map(lambda x: x['userName'], userInfo))\n",
        "        userId = list(map(lambda x: x['userId'], userInfo))\n",
        "        redId = list(map(lambda x: x['redId'], userInfo))\n",
        "        favLikeNum = list(map(lambda x: x['favLikeNum'], userInfo))\n",
        "        fansNum = list(map(lambda x: x['fansNum'], userInfo))\n",
        "        noteNum = list(map(lambda x: x['noteNum'], userInfo))\n",
        "        mcnUserId = list(map(lambda x: x['mcnUserId'], userInfo))\n",
        "        startTime = list(map(lambda x: x['startTime'], userInfo))\n",
        "        endTime=list(map(lambda x: x['endTime'], userInfo))\n",
        "        businessType = list(map(lambda x: x['businessType'], userInfo))\n",
        "        data=pd.DataFrame({'names':names,'userId':userId,'redId':redId,'favLikeNum':favLikeNum,'fansNum':fansNum,'noteNum':noteNum,'mcnUserId':mcnUserId,'startTime':startTime,\n",
        "                        'endTime':endTime,'businessType':businessType\n",
        "                        })\n",
        "        data[\"startTime\"] = data[\"startTime\"].apply(lambda x: pd.to_datetime(x, unit='ms')+pd.Timedelta(hours=8) if x != 0 else 0)\n",
        "        data[\"endTime\"] = data[\"endTime\"].apply(lambda x: pd.to_datetime(x, unit='ms')+pd.Timedelta(hours=8) if x != 0 else 0)\n",
        "        data.columns=[\"用户昵称\",'用户ID','小红书ID','获赞数','粉丝数','笔记数','mcnID','合作开始时间','合作结束时间','合作类型']\n",
        "        data[\"合作类型\"] = data[\"合作类型\"].map({1: '博主合作业务', 2: '买手合作业务'})\n",
        "        data['mcnID']=data['mcnID'].map(cookie.mcnUserId)\n",
        "        data[\"抓取时间\"]=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        return data\n",
        "    def data_创作者中心_签约关系列表_已终止(self,cookie_name):\n",
        "        get_json_data=self.get_创作者中心_签约关系列表_已终止合作(url=api_json['创作者中心_签约关系列表_已终止合作'],cookie=cookie.czzzx_cookie_json[cookie_name],headers=cookie.czzzx_headers_json[cookie_name])\n",
        "        logger.info(f\"{cookie_name} 创作者中心_签约关系列表 数据获取完成,共 {len(get_json_data)} 条数据\")\n",
        "        f_data=self.parse_get_创作者中心_签约关系列表_已终止合作(get_json_data)\n",
        "        return f_data\n",
        "    \n",
        "\n",
        "    def get_创作者中心_签约邀请(self,url,cookie,headers,applyType):\n",
        "        \n",
        "        userInfo=[]\n",
        "        session=requests.Session()\n",
        "        retry_strategy = Retry(\n",
        "                total=5,  # 总重试次数\n",
        "                backoff_factor=10,  # 退避因子\n",
        "                status_forcelist=[429, 500, 502, 503, 504],  # 需要重试的HTTP状态码\n",
        "                allowed_methods=[\"GET\"]  # 允许重试的方法\n",
        "            )\n",
        "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "        session.mount(\"http://\", adapter)\n",
        "        session.mount(\"https://\", adapter)\n",
        "\n",
        "        params={\n",
        "            'pageNum':'1',\n",
        "            'pageSize':'100',\n",
        "            'status':'0',\n",
        "            'applyTypes':applyType\n",
        "        }\n",
        "        try:\n",
        "            #proxies暂无余量，0代替，可替换为proxy_pool.get_proxy()即可获取代理池\n",
        "            total_page=session.get(url=url,cookies=cookie,headers=headers,timeout=30,verify=False,proxies=0).json()\n",
        "            total=total_page['data']['total']\n",
        "            total_pages=(total//100)+1\n",
        "            logger.info(f\"创作者中心_签约邀请: {total}, 创作者中心_签约邀请: {total_pages}\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logger.error(f\"请求失败，错误: {e}\")\n",
        "            return None\n",
        "        \n",
        "        for page in range(1,total_pages+1):\n",
        "            params['pageNum']=str(page)\n",
        "            try:\n",
        "                response = session.get(\n",
        "                    url=url,\n",
        "                    params=params,\n",
        "                    cookies=cookie,\n",
        "                    headers=headers,\n",
        "                    timeout=30,\n",
        "                    verify=False,\n",
        "                    #同理proxies\n",
        "                    proxies=0\n",
        "                    )\n",
        "                response.raise_for_status()  # 如果响应状态码不是200，抛出异常\n",
        "                logger.info(f\"请求成功，状态码: {response.status_code}, 页码: {page}\")\n",
        "                userInfo.append(response.json()[\"data\"][\"applies\"])\n",
        "                    \n",
        "            except requests.exceptions.RequestException as e:\n",
        "                logger.error(f\"请求失败，错误: {e}, 页码: {page}\")\n",
        "                return None\n",
        "        return userInfo\n",
        "    def parse_get_创作者中心_签约邀请(self,data,cookie_name):\n",
        "        data=list(chain.from_iterable(data))\n",
        "        applyNo = list(map(lambda x: x['applyNo'], data))\n",
        "        businessType = list(map(lambda x: x['businessType'], data))\n",
        "        applyType = list(map(lambda x: x['applyType'], data))\n",
        "        userId = list(map(lambda x: x['userId'], data))\n",
        "        redId = list(map(lambda x: x['redId'], data))\n",
        "        userName = list(map(lambda x: x['userName'], data))\n",
        "        fansNum = list(map(lambda x: x['fansNum'], data))\n",
        "        applyStatus = list(map(lambda x: x['applyStatus'], data))\n",
        "        updateTime = list(map(lambda x: x['updateTime'], data))    \n",
        "        submitUserType = list(map(lambda x: x['submitUserType'], data))    \n",
        "\n",
        "\n",
        "        f_data=pd.DataFrame({'applyNo':applyNo,'userName':userName,'redId':redId,'applyType':applyType,'businessType':businessType,'userId':userId,'fansNum':fansNum,'applyStatus':applyStatus,'updateTime':updateTime,'submitUserType':submitUserType})\n",
        "        f_data[\"updateTime\"] = f_data[\"updateTime\"].apply(lambda x: pd.to_datetime(x, unit='ms')+pd.Timedelta(hours=8) if x != 0 else 0)\n",
        "        f_data[\"applyType\"] = f_data[\"applyType\"].map({1:\"签约\",2:\"续约\",3:\"解约\"})\n",
        "        f_data[\"applyStatus\"] = f_data[\"applyStatus\"].map({1:\"待确认\",2:\"已通过\",3:\"已拒绝\",4:\"已撤回\",6:'超时未确认'})\n",
        "        f_data[\"businessType\"] = f_data[\"businessType\"].map({1:\"博主合作业务\",2:\"买手合作业务\",3:\"买手合作业务、博主合作业务\"})\n",
        "        f_data.columns=[\"申请编号\",'用户昵称','小红书ID','申请类型','业务类型','用户ID','粉丝数','申请状态','更新时间','发起方']\n",
        "        f_data[\"抓取时间\"]=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        f_data[\"来源\"]=cookie_name\n",
        "       \n",
        "\n",
        "        return f_data  \n",
        "    def data_创作者中心_签约邀请(self,cookie_name,applyType):\n",
        "        get_json_data=self.get_创作者中心_签约邀请(url=api_json['创作者中心_签约邀请'],cookie=cookie.czzzx_cookie_json[cookie_name],headers=cookie.czzzx_headers_json[cookie_name],applyType=applyType)\n",
        "        logger.info(f\"{cookie_name} data_创作者中心_签约邀请 数据获取完成,共 {len(get_json_data)} 条数据\")\n",
        "        f_data=self.parse_get_创作者中心_签约邀请(data=get_json_data,cookie_name=cookie_name)\n",
        "        return f_data\n",
        "\n",
        "\n",
        "\n",
        "    def get_signInfo(self,applyNo,cookie,headers,proxy):\n",
        "        url='https://creator.xiaohongshu.com/api/galaxy/sign/apply/'+applyNo+'/detail'\n",
        "            \n",
        "\n",
        "        session=requests.Session()\n",
        "        retry_strategy = Retry(\n",
        "                total=5,  # 总重试次数\n",
        "                backoff_factor=10,  # 退避因子\n",
        "                status_forcelist=[429, 500, 502, 503, 504],  # 需要重试的HTTP状态码\n",
        "                allowed_methods=[\"GET\"]  # 允许重试的方法\n",
        "            )\n",
        "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "        session.mount(\"http://\", adapter)\n",
        "        session.mount(\"https://\", adapter)\n",
        "        try:\n",
        "            response = session.get(\n",
        "                url=url,\n",
        "                cookies=cookie,\n",
        "                headers=headers,\n",
        "                timeout=30,\n",
        "                verify=False,\n",
        "                proxies=proxy_pool.get_proxy()\n",
        "                )\n",
        "            print(response.status_code)\n",
        "            data=response.json()\n",
        "            return data\n",
        "        except Exception as e:\n",
        "            logger.error(f\"{applyNo}请求失败，错误: {e}\")\n",
        "            print(response.text)\n",
        "    def parse_get_signInfo(self,data):\n",
        "        applyNo = data[\"applyNo\"]\n",
        "        businessType =data[\"businessType\"]\n",
        "        applyType = data['applyType']\n",
        "        userId=data['signUser']['userId']\n",
        "        userName=data['signUser']['userName']\n",
        "        redId=data['signUser']['redId']\n",
        "        fansNum=data['signUser']['fansNum']\n",
        "        favLikeNum=data['signUser']['favLikeNum']\n",
        "\n",
        "        applyStatus = data['applyStatus']\n",
        "        updateTime = data['updateTime']\n",
        "        startTime=data['startTime']\n",
        "        endTime=data['endTime']\n",
        "        \n",
        "        f_data=[applyNo,userName,redId,applyType,businessType,userId,fansNum,favLikeNum,applyStatus,updateTime,startTime,endTime]\n",
        "        return f_data\n",
        "    def get_All_signInfo(self,data,cookie_name):\n",
        "        all_data=[]\n",
        "        for i in range(len(data)):\n",
        "            # print(i,data[i])\n",
        "            if data[i].get('success') ==False or data[i].get('error'):\n",
        "                continue\n",
        "            else:\n",
        "                parsed_data=self.parse_get_signInfo(data[i][\"data\"])\n",
        "                all_data.append(parsed_data)\n",
        "        f_data=pd.DataFrame(all_data,columns=['申请编号','用户昵称','小红书ID','申请类型','业务类型','用户ID','粉丝数','获赞数','申请状态','更新时间','合作开始时间','合作结束时间'])\n",
        "        f_data[\"更新时间\"] = f_data[\"更新时间\"].apply(lambda x: pd.to_datetime(x, unit='ms')+pd.Timedelta(hours=8) if x != 0 else 0)\n",
        "        f_data[\"合作开始时间\"] = f_data[\"合作开始时间\"].apply(lambda x: pd.to_datetime(x, unit='ms')+pd.Timedelta(hours=8) if x != 0 else 0)\n",
        "        f_data[\"合作结束时间\"] = f_data[\"合作结束时间\"].apply(lambda x: pd.to_datetime(x, unit='ms')+pd.Timedelta(hours=8) if x != 0 else 0)\n",
        "        f_data[\"申请类型\"] = f_data[\"申请类型\"].map({1:\"签约\",2:\"续约\",3:\"解约\"})\n",
        "        f_data[\"申请状态\"] = f_data[\"申请状态\"].map({1:\"待确认\",2:\"已通过\",3:\"已拒绝\",4:\"已撤回\",6:'超时未确认'})\n",
        "        f_data[\"业务类型\"] = f_data[\"业务类型\"].map({1:\"博主合作业务\",2:\"买手合作业务\",3:\"买手合作业务、博主合作业务\"})\n",
        "        f_data[\"抓取时间\"]=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        f_data[\"来源\"]=cookie_name\n",
        "\n",
        "        return f_data\n",
        "\n",
        "        \n",
        "\n",
        "    def get_创作者中心_机构总览(self, cookie_name, max_retries: int = 5):\n",
        "        url = api_json[\"创作者中心_机构总览\"]\n",
        "        data = []\n",
        "        try:\n",
        "            resp_json = self._get_json_with_retry(\n",
        "                url=url,\n",
        "                cookie_name=cookie_name,\n",
        "                timeout=30,\n",
        "                verify=False,\n",
        "                max_retries=max_retries,\n",
        "                retry_on_success_false=True,\n",
        "            )\n",
        "            response_data = resp_json.get(\"data\")\n",
        "            if not isinstance(response_data, dict):\n",
        "                raise RuntimeError(f\"机构总览 data结构异常(非dict): {response_data}\")\n",
        "\n",
        "            kolNum = response_data[\"kolNum\"]\n",
        "            cooperNum = response_data[\"cooperNum\"]\n",
        "            cpsPrice = response_data[\"cpsPrice\"]\n",
        "            # ps:接口中datekey为统计截至日期，比当前date.day-1\n",
        "            dateKey = response_data[\"dateKey\"]\n",
        "\n",
        "            data.append([dateKey, kolNum, cooperNum, cpsPrice])\n",
        "            data_F = pd.DataFrame(data, columns=[\"日期\", \"已签约博主\", \"博主合作\", \" 买手合作金额\"])\n",
        "            data_F[\"来源\"] = cookie_name\n",
        "            data_F[\"抓取时间\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            return data_F\n",
        "        except Exception as e:\n",
        "            logger.error(f\"机构总览 获取失败: {e}\")\n",
        "            raise\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    def get_创作者中心_机构总览_数据概览(self, cookie_name, max_retries: int = 5):\n",
        "        url = api_json[\"创作者中心_数据概览\"]\n",
        "        params = {\"time\": \"30\"}\n",
        "\n",
        "        resp_json = self._get_json_with_retry(\n",
        "            url=url,\n",
        "            cookie_name=cookie_name,\n",
        "            params=params,\n",
        "            timeout=30,\n",
        "            verify=False,\n",
        "            max_retries=max_retries,\n",
        "            retry_on_success_false=True,\n",
        "        )\n",
        "\n",
        "        response_data = resp_json.get(\"data\")\n",
        "        if not isinstance(response_data, dict):\n",
        "            raise RuntimeError(f\"机构总览_数据概览 data结构异常(非dict): {response_data}\")\n",
        "\n",
        "        # 关键字段校验（避免偶发结构变化导致 KeyError 不易定位）\n",
        "        required_keys = [\n",
        "            \"fansNum\",\n",
        "            \"followNum\",\n",
        "            \"unFollowNum\",\n",
        "            \"cooperNum\",\n",
        "            \"cooperPrice\",\n",
        "            \"cpsPrice\",\n",
        "            \"dateKey\",\n",
        "            \"video\",\n",
        "            \"picture\",\n",
        "        ]\n",
        "        missing = [k for k in required_keys if k not in response_data]\n",
        "        if missing:\n",
        "            raise KeyError(f\"接口data缺少字段: {missing}\")\n",
        "\n",
        "        fansNum = response_data[\"fansNum\"]\n",
        "        followNum = response_data[\"followNum\"]\n",
        "        unFollowNum = response_data[\"unFollowNum\"]\n",
        "        cooperNum = response_data[\"cooperNum\"]\n",
        "        cooperPrice = response_data[\"cooperPrice\"]\n",
        "        cpsPrice = response_data[\"cpsPrice\"]\n",
        "        dateKey = response_data[\"dateKey\"]\n",
        "        video_noteNum = response_data[\"video\"][\"noteNum\"]\n",
        "        video_readNum = response_data[\"video\"][\"readNum\"]\n",
        "        picture_noteNum = response_data[\"picture\"][\"noteNum\"]\n",
        "        picture_readNum = response_data[\"picture\"][\"readNum\"]\n",
        "\n",
        "        data = [\n",
        "            [\n",
        "                dateKey,\n",
        "                fansNum,\n",
        "                followNum,\n",
        "                unFollowNum,\n",
        "                cooperNum,\n",
        "                cooperPrice,\n",
        "                cpsPrice,\n",
        "                video_noteNum,\n",
        "                video_readNum,\n",
        "                picture_noteNum,\n",
        "                picture_readNum,\n",
        "            ]\n",
        "        ]\n",
        "        data_F = pd.DataFrame(\n",
        "            data,\n",
        "            columns=[\n",
        "                \"日期\",\n",
        "                \"总粉丝\",\n",
        "                \"新增粉丝数\",\n",
        "                \"流失粉丝数\",\n",
        "                \"博主合作单数\",\n",
        "                \"博主合作金额\",\n",
        "                \"买手合作金额\",\n",
        "                \"视频笔记发布量\",\n",
        "                \"视频笔记播放量\",\n",
        "                \"图文笔记发布量\",\n",
        "                \"图文笔记阅读量\",\n",
        "            ],\n",
        "        )\n",
        "        data_F[\"统计周期\"] = \"近30天\"\n",
        "        data_F[\"统计周期start\"] = str(datetime.date(pd.to_datetime(dateKey) - pd.Timedelta(days=30)))\n",
        "        data_F[\"统计周期end\"] = dateKey\n",
        "        data_F[\"统计起止时间\"] = data_F[\"统计周期start\"] + \"~\" + dateKey\n",
        "        data_F[\"来源\"] = cookie_name\n",
        "        data_F[\"抓取时间\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        return data_F\n",
        "            \n",
        "    \n",
        "    \n",
        "    def get_创作者中心_博主排名_涨粉能力排名(self,cookie_name):\n",
        "        data=[]\n",
        "        url=api_json[\"创作者中心_博主排名_涨粉能力排名\"]\n",
        "        params = {\n",
        "    'rankField': 'follow_num',\n",
        "    'time': '30',\n",
        "    'pageNum': '1',\n",
        "    'pageSize': '10',\n",
        "}\n",
        "        try:\n",
        "            resp_json = self._get_json_with_retry(\n",
        "                url=url,\n",
        "                cookie_name=cookie_name,\n",
        "                params=params,\n",
        "                timeout=30,\n",
        "                verify=False,\n",
        "                max_retries=5,\n",
        "                retry_on_success_false=True,\n",
        "            )\n",
        "            response_data = resp_json[\"data\"][\"kols\"]\n",
        "            userIds=list(map(lambda x: x['userId'], response_data))\n",
        "            userNames=list(map(lambda x: x['userName'], response_data))\n",
        "            tags=list(map(lambda x: x['tags'], response_data))\n",
        "            followNum=list(map(lambda x: x['followNum'], response_data))\n",
        "            fansNum=list(map(lambda x: x['fansNum'], response_data))\n",
        "            activeFansNum=list(map(lambda x: x['activeFansNum'], response_data))\n",
        "            data.append([userIds,userNames,tags,followNum,fansNum,activeFansNum])\n",
        "            data_F=pd.DataFrame({\"用户ID\":userIds,\n",
        "                                 '用户昵称':userNames,\n",
        "                                 '账号标签':tags,\n",
        "                                 '涨粉数':followNum,\n",
        "                                 '总粉丝数':fansNum,\n",
        "                                 '总活跃粉丝数':activeFansNum})\n",
        "            data_F[\"统计周期\"]='近30天'\n",
        "            data_F[\"统计周期start\"]=str(pd.to_datetime(datetime.now()-pd.Timedelta(days=31)).strftime(\"%Y-%m-%d\"))\n",
        "            data_F[\"统计周期end\"]=str(pd.to_datetime(datetime.now()-pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "            data_F[\"统计起止时间\"]=data_F[\"统计周期start\"]+\"~\"+data_F[\"统计周期end\"]\n",
        "            \n",
        "\n",
        "            data_F[\"账号标签\"]=data_F[\"账号标签\"].apply(lambda x:str(x).replace(\"[\",''))\n",
        "            data_F[\"账号标签\"]=data_F[\"账号标签\"].apply(lambda x:str(x).replace(\"]\",''))\n",
        "            data_F[\"抓取时间\"]=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "            data_F[\"来源\"]=cookie_name\n",
        "            return data_F\n",
        "        except Exception as e:\n",
        "            logger.error(f\"涨粉能力排名 获取失败: {e}\")\n",
        "            raise\n",
        "    def get_创作者中心_博主排名_博主合作排名(self,cookie_name):\n",
        "        data=[]\n",
        "        url=api_json[\"创作者中心_博主排名_涨粉能力排名\"]\n",
        "        params = {\n",
        "        'rankField': 'cooper_num',\n",
        "        'time': '30',\n",
        "        'pageNum': '1',\n",
        "        'pageSize': '10',\n",
        "    }\n",
        "        try:\n",
        "            resp_json = self._get_json_with_retry(\n",
        "                url=url,\n",
        "                cookie_name=cookie_name,\n",
        "                params=params,\n",
        "                timeout=30,\n",
        "                verify=False,\n",
        "                max_retries=5,\n",
        "                retry_on_success_false=True,\n",
        "            )\n",
        "            response_data=resp_json[\"data\"][\"kols\"]\n",
        "            userIds=list(map(lambda x: x['userId'], response_data))\n",
        "            userNames=list(map(lambda x: x['userName'], response_data))\n",
        "            tags=list(map(lambda x: x['tags'], response_data))\n",
        "            cooperNum=list(map(lambda x: x['cooperNum'], response_data))\n",
        "            cooperPrice=list(map(lambda x: x['cooperPrice'], response_data))\n",
        "            l1mCooperPrice=list(map(lambda x: x['l1mCooperPrice'], response_data))\n",
        "            data.append([userIds,userNames,tags,cooperNum,cooperPrice,l1mCooperPrice])\n",
        "            data_F=pd.DataFrame({\"用户ID\":userIds,\n",
        "                                 '用户昵称':userNames,\n",
        "                                 '账号标签':tags,\n",
        "                                 '博主合作单数':cooperNum,\n",
        "                                 '博主合作金额':cooperPrice,\n",
        "                                 '上月结算金额':l1mCooperPrice})\n",
        "            data_F[\"统计周期\"]='近30天'\n",
        "            data_F[\"统计周期start\"]=str(pd.to_datetime(datetime.now()-pd.Timedelta(days=31)).strftime(\"%Y-%m-%d\"))\n",
        "            data_F[\"统计周期end\"]=str(pd.to_datetime(datetime.now()-pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "            data_F[\"统计起止时间\"]=data_F[\"统计周期start\"]+'~'+data_F[\"统计周期end\"]\n",
        "            \n",
        "\n",
        "            data_F[\"账号标签\"]=data_F[\"账号标签\"].apply(lambda x:str(x).replace(\"[\",''))\n",
        "            data_F[\"账号标签\"]=data_F[\"账号标签\"].apply(lambda x:str(x).replace(\"]\",''))\n",
        "            data_F[\"抓取时间\"]=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "            data_F[\"来源\"]=cookie_name\n",
        "            return data_F\n",
        "        except Exception as e:\n",
        "            logger.error(f\"博主合作排名 获取失败: {e}\")\n",
        "            raise   \n",
        "   \n",
        "    def get_创作者中心_博主排名_买手合作排名(self,cookie_name):\n",
        "        data=[]\n",
        "        url=api_json[\"创作者中心_博主排名_涨粉能力排名\"]\n",
        "        params = {\n",
        "        'rankField': 'cps_price',\n",
        "        'time': '30',\n",
        "        'pageNum': '1',\n",
        "        'pageSize': '10',\n",
        "    }\n",
        "        try:\n",
        "            resp_json = self._get_json_with_retry(\n",
        "                url=url,\n",
        "                cookie_name=cookie_name,\n",
        "                params=params,\n",
        "                timeout=30,\n",
        "                verify=False,\n",
        "                max_retries=5,\n",
        "                retry_on_success_false=True,\n",
        "            )\n",
        "            response_data=resp_json[\"data\"][\"kols\"]\n",
        "            userIds=list(map(lambda x: x['userId'], response_data))\n",
        "            userNames=list(map(lambda x: x['userName'], response_data))\n",
        "            tags=list(map(lambda x: x['tags'], response_data))\n",
        "            cpsPrice=list(map(lambda x: x['cpsPrice'], response_data))\n",
        "            noteCpsPrice=list(map(lambda x: x['noteCpsPrice'], response_data))\n",
        "            liveCpsPrice=list(map(lambda x: x['liveCpsPrice'], response_data))\n",
        "            data.append([userIds,userNames,tags,cpsPrice,noteCpsPrice,liveCpsPrice])\n",
        "            data_F=pd.DataFrame({\"用户ID\":userIds,\n",
        "                                 '用户昵称':userNames,\n",
        "                                 '账号标签':tags,\n",
        "                                 '买手合作结算总金额':cpsPrice,\n",
        "                                 '笔记带货结算金额':noteCpsPrice,\n",
        "                                 '直播带货结算金额':liveCpsPrice})\n",
        "            data_F[\"统计周期\"]='近30天'\n",
        "            data_F[\"统计周期start\"]=str(pd.to_datetime(datetime.now()-pd.Timedelta(days=31)).strftime(\"%Y-%m-%d\"))\n",
        "            data_F[\"统计周期end\"]=str(pd.to_datetime(datetime.now()-pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "            data_F[\"统计起止时间\"]=data_F[\"统计周期start\"]+'~'+data_F[\"统计周期end\"]\n",
        "            \n",
        "\n",
        "            data_F[\"账号标签\"]=data_F[\"账号标签\"].apply(lambda x:str(x).replace(\"[\",''))\n",
        "            data_F[\"账号标签\"]=data_F[\"账号标签\"].apply(lambda x:str(x).replace(\"]\",''))\n",
        "            data_F[\"抓取时间\"]=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "            data_F[\"来源\"]=cookie_name\n",
        "            return data_F\n",
        "        except Exception as e:\n",
        "            logger.error(f\"买手合作排名 获取失败: {e}\")\n",
        "            raise      \n",
        "   \n",
        "    def get_创作者中心_笔记排名_笔记播放or阅读排名(self,cookie_name):\n",
        "            data=[]\n",
        "            url=api_json[\"创作者中心_笔记排名\"]\n",
        "            params = {\n",
        "            'rankField': 'read_num',\n",
        "            'time': '30',\n",
        "            'pageNum': '1',\n",
        "            'pageSize': '10',\n",
        "        }\n",
        "            try:\n",
        "                resp_json = self._get_json_with_retry(\n",
        "                    url=url,\n",
        "                    cookie_name=cookie_name,\n",
        "                    params=params,\n",
        "                    timeout=30,\n",
        "                    verify=False,\n",
        "                    max_retries=5,\n",
        "                    retry_on_success_false=True,\n",
        "                )\n",
        "                # return resp_json\n",
        "                response_data=resp_json[\"data\"][\"notes\"]\n",
        "                userIds=list(map(lambda x: x['userId'], response_data))\n",
        "                userNames=list(map(lambda x: x['userName'], response_data))\n",
        "                noteId=list(map(lambda x: x['noteId'], response_data))\n",
        "                noteType=list(map(lambda x: x['noteType'], response_data))\n",
        "                noteDesc=list(map(lambda x: x['noteDesc'], response_data))\n",
        "                readNum=list(map(lambda x: x['readNum'], response_data))\n",
        "\n",
        "                videoViews=list(map(lambda x: x['videoViews'], response_data))\n",
        "                finishRate=list(map(lambda x: x['finishRate'], response_data))\n",
        "                followNum=list(map(lambda x: x['followNum'], response_data))\n",
        "                xsecSource=list(map(lambda x: x['xsecSource'], response_data))\n",
        "                xsecToken=list(map(lambda x: x['xsecToken'], response_data))\n",
        "                data.append([userIds,userNames,noteId,noteType,noteDesc,readNum,videoViews,finishRate,followNum,xsecSource,xsecToken])\n",
        "                data_F=pd.DataFrame({\"用户ID\":userIds,\n",
        "                                    '用户昵称':userNames,\n",
        "                                    '笔记ID':noteId,\n",
        "                                    '笔记类型':noteType,\n",
        "                                    '笔记标题':noteDesc,\n",
        "                                    '播放数':videoViews,\n",
        "                                    \"阅读数\":readNum,\n",
        "                                    '完播率':finishRate,\n",
        "                                    '涨粉数':followNum,\n",
        "                                    'xsecSource':xsecSource,\n",
        "                                    'xsecToken':xsecToken,\n",
        "                                    })\n",
        "                data_F[\"统计周期\"]='近30天'\n",
        "                data_F[\"统计周期start\"]=str(pd.to_datetime(datetime.now()-pd.Timedelta(days=31)).strftime(\"%Y-%m-%d\"))\n",
        "                data_F[\"统计周期end\"]=str(pd.to_datetime(datetime.now()-pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "                data_F[\"统计起止时间\"]=data_F[\"统计周期start\"]+'~'+data_F[\"统计周期end\"]\n",
        "                data_F[\"笔记类型\"]=data_F[\"笔记类型\"].map({1:\"图文\",2:\"视频\"})\n",
        "                data_F.loc[data_F[\"笔记类型\"]=='图文','播放数']=data_F.loc[data_F[\"笔记类型\"]=='图文','阅读数']\n",
        "                data_F.drop(columns=[\"阅读数\"],inplace=True)\n",
        "                data_F[\"抓取时间\"]=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "                data_F[\"来源\"]=cookie_name\n",
        "                data_F[\"视频URL\"]='https://www.xiaohongshu.com/explore/'+data_F[\"笔记ID\"]+\"?xsec_source=\"+data_F[\"xsecSource\"]+\"&xsec_token=\"+data_F[\"xsecToken\"]\n",
        "                return data_F\n",
        "            except Exception as e:\n",
        "                logger.error(f\"笔记播放/阅读排名 获取失败: {e}\")\n",
        "                raise\n",
        "\n",
        "    \n",
        "    def get_创作者中心_笔记排名_笔记涨粉能力排名(self,cookie_name):\n",
        "            data=[]\n",
        "            url=api_json[\"创作者中心_笔记排名\"]\n",
        "            params = {\n",
        "            'rankField': 'follow_num',\n",
        "            'time': '30',\n",
        "            'pageNum': '1',\n",
        "            'pageSize': '10',\n",
        "        }\n",
        "            try:\n",
        "                resp_json = self._get_json_with_retry(\n",
        "                    url=url,\n",
        "                    cookie_name=cookie_name,\n",
        "                    params=params,\n",
        "                    timeout=30,\n",
        "                    verify=False,\n",
        "                    max_retries=5,\n",
        "                    retry_on_success_false=True,\n",
        "                )\n",
        "                # return resp_json\n",
        "                response_data=resp_json[\"data\"][\"notes\"]\n",
        "                userIds=list(map(lambda x: x['userId'], response_data))\n",
        "                userNames=list(map(lambda x: x['userName'], response_data))\n",
        "                noteId=list(map(lambda x: x['noteId'], response_data))\n",
        "                noteType=list(map(lambda x: x['noteType'], response_data))\n",
        "                noteDesc=list(map(lambda x: x['noteDesc'], response_data))\n",
        "                readNum=list(map(lambda x: x['readNum'], response_data))\n",
        "\n",
        "                videoViews=list(map(lambda x: x['videoViews'], response_data))\n",
        "                finishRate=list(map(lambda x: x['finishRate'], response_data))\n",
        "                followNum=list(map(lambda x: x['followNum'], response_data))\n",
        "                xsecSource=list(map(lambda x: x['xsecSource'], response_data))\n",
        "                xsecToken=list(map(lambda x: x['xsecToken'], response_data))\n",
        "                data.append([userIds,userNames,noteId,noteType,noteDesc,readNum,videoViews,finishRate,followNum,xsecSource,xsecToken])\n",
        "                data_F=pd.DataFrame({\"用户ID\":userIds,\n",
        "                                    '用户昵称':userNames,\n",
        "                                    '笔记ID':noteId,\n",
        "                                    '笔记类型':noteType,\n",
        "                                    '笔记标题':noteDesc,\n",
        "                                    '播放数':videoViews,\n",
        "                                    \"阅读数\":readNum,\n",
        "                                    '完播率':finishRate,\n",
        "                                    '涨粉数':followNum,\n",
        "                                    'xsecSource':xsecSource,\n",
        "                                    'xsecToken':xsecToken,\n",
        "                                    })\n",
        "                data_F[\"统计周期\"]='近30天'\n",
        "                data_F[\"统计周期start\"]=str(pd.to_datetime(datetime.now()-pd.Timedelta(days=31)).strftime(\"%Y-%m-%d\"))\n",
        "                data_F[\"统计周期end\"]=str(pd.to_datetime(datetime.now()-pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "                data_F[\"统计起止时间\"]=data_F[\"统计周期start\"]+'~'+data_F[\"统计周期end\"]\n",
        "                data_F[\"笔记类型\"]=data_F[\"笔记类型\"].map({1:\"图文\",2:\"视频\"})\n",
        "                data_F.loc[data_F[\"笔记类型\"]=='图文','播放数']=data_F.loc[data_F[\"笔记类型\"]=='图文','阅读数']\n",
        "                data_F.drop(columns=[\"阅读数\"],inplace=True)\n",
        "                data_F[\"抓取时间\"]=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "                data_F[\"来源\"]=cookie_name\n",
        "                data_F[\"视频URL\"]='https://www.xiaohongshu.com/explore/'+data_F[\"笔记ID\"]+\"?xsec_source=\"+data_F[\"xsecSource\"]+\"&xsec_token=\"+data_F[\"xsecToken\"]\n",
        "                return data_F\n",
        "            except Exception as e:\n",
        "                logger.error(f\"笔记涨粉能力排名 获取失败: {e}\")\n",
        "                raise\n",
        "            \n",
        "    def get_达人数据_笔记数据概览(self, cookie_name, times, params, proxy, max_retries=5):\n",
        "        params_input = dict(params)\n",
        "        params_input[\"time\"] = str(times)\n",
        "        userId = params_input[\"userId\"]\n",
        "        url = api_json[\"创作者中心_达人数据_笔记概览\"]\n",
        "        last_exc = None\n",
        "        for attempt in range(1, max_retries + 1):\n",
        "            try:\n",
        "                response = self._session.get(\n",
        "                    url=url,\n",
        "                    params=params_input,\n",
        "                    cookies=cookie.czzzx_cookie_json[cookie_name],\n",
        "                    headers=cookie.czzzx_headers_json[cookie_name],\n",
        "                    proxies=proxy if proxy else None,\n",
        "                    timeout=30,\n",
        "                    verify=False,\n",
        "                )\n",
        "                response.raise_for_status()\n",
        "                resp_json = response.json()\n",
        "                if isinstance(resp_json, dict) and resp_json.get(\"success\") is False:\n",
        "                    raise RuntimeError(f\"接口返回success=false: {resp_json.get('msg')}\")\n",
        "                response_data = resp_json[\"data\"]\n",
        "\n",
        "                tt_dailyAvgVideoViewNum = response_data[\"noteQuota\"][\"dailyAvgVideoViewNum\"]\n",
        "                tt_dailyAvgPictureReadNum = response_data[\"noteQuota\"][\"dailyAvgPictureReadNum\"]\n",
        "                tt_dailyAvgLikeNum = response_data[\"noteQuota\"][\"dailyAvgLikeNum\"]\n",
        "                tt_dailyAvgFavNum = response_data[\"noteQuota\"][\"dailyAvgFavNum\"]\n",
        "                tt_dailyAvgCmtNum = response_data[\"noteQuota\"][\"dailyAvgCmtNum\"]\n",
        "                tt_dailyAvgShareNum = response_data[\"noteQuota\"][\"dailyAvgShareNum\"]\n",
        "\n",
        "                video_dailyAvgLikeNum = response_data[\"videoQuota\"][\"dailyAvgLikeNum\"]\n",
        "                video_dailyAvgFavNum = response_data[\"videoQuota\"][\"dailyAvgFavNum\"]\n",
        "                video_dailyAvgCmtNum = response_data[\"videoQuota\"][\"dailyAvgCmtNum\"]\n",
        "                video_dailyAvgShareNum = response_data[\"videoQuota\"][\"dailyAvgShareNum\"]\n",
        "\n",
        "                pic_dailyAvgLikeNum = response_data[\"pictureQuota\"][\"dailyAvgLikeNum\"]\n",
        "                pic_dailyAvgFavNum = response_data[\"pictureQuota\"][\"dailyAvgFavNum\"]\n",
        "                pic_dailyAvgCmtNum = response_data[\"pictureQuota\"][\"dailyAvgCmtNum\"]\n",
        "                pic_dailyAvgShareNum = response_data[\"pictureQuota\"][\"dailyAvgShareNum\"]\n",
        "\n",
        "                return {\n",
        "                    \"用户ID\": userId,\n",
        "                    \"日均视频播放量\": tt_dailyAvgVideoViewNum,\n",
        "                    \"日均图文阅读数\": tt_dailyAvgPictureReadNum,\n",
        "                    \"日均评论数\": tt_dailyAvgCmtNum,\n",
        "                    \"日均分享数\": tt_dailyAvgShareNum,\n",
        "                    \"日均收藏数\": tt_dailyAvgFavNum,\n",
        "                    \"日均点赞数\": tt_dailyAvgLikeNum,\n",
        "                    \"video_日均点赞数\": video_dailyAvgLikeNum,\n",
        "                    \"video_日均收藏数\": video_dailyAvgFavNum,\n",
        "                    \"video_日均评论数\": video_dailyAvgCmtNum,\n",
        "                    \"video_日均分享数\": video_dailyAvgShareNum,\n",
        "                    \"picture_日均点赞数\": pic_dailyAvgLikeNum,\n",
        "                    \"picture_日均收藏数\": pic_dailyAvgFavNum,\n",
        "                    \"picture_日均评论数\": pic_dailyAvgCmtNum,\n",
        "                    \"picture_日均分享数\": pic_dailyAvgShareNum,\n",
        "                    \"来源\": cookie_name,\n",
        "                    \"统计周期\": \"近\" + str(times) + \"天\",\n",
        "                    \"抓取时间\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                }\n",
        "            except Exception as e:\n",
        "                last_exc = e\n",
        "                logger.warning(f\"达人数据_笔记数据概览 userId={userId} 第{attempt}/{max_retries}次失败: {e}\")\n",
        "                if attempt < max_retries:\n",
        "                    time.sleep(min(2 ** (attempt - 1), 8))\n",
        "        raise RuntimeError(f\"达人数据_笔记数据概览 连续失败{max_retries}次 userId={userId}\") from last_exc    \n",
        "    def fetch_single_达人数据(self,cookie_name,params,times,proxy):\n",
        "        # proxy_one=proxy_pool.get_proxy()\n",
        "        response = self.get_达人数据_笔记数据概览(cookie_name=cookie_name,times=times,params=params,proxy=proxy)\n",
        "        return response\n",
        "    def batch_fetch_all_with_progress_达人数据(self,cookie_name,params, max_workers,times,proxy):\n",
        "        \"\"\"批量并发请求\"\"\"\n",
        "        results = []\n",
        "        total_tasks = len(params)\n",
        "        \n",
        "        print(f\"开始批量请求，共 {total_tasks} 个任务，并发数: {max_workers}\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "            # 提交所有任务\n",
        "            future_to_url = {executor.submit(self.fetch_single_达人数据, cookie_name=cookie_name,params=param,times=times,proxy=proxy): param for param in params}\n",
        "            \n",
        "            # 使用tqdm显示进度\n",
        "            with tqdm(total=total_tasks, desc=\"处理进度\", unit=\"个\", ncols=100) as pbar:\n",
        "                # 按完成顺序获取结果\n",
        "                for future in as_completed(future_to_url):\n",
        "                    url = future_to_url[future]\n",
        "                    try:\n",
        "                        result = future.result()\n",
        "                        results.append(result)\n",
        "                        pbar.update(1)  # 更新进度条\n",
        "                        pbar.set_postfix_str(f\"已处理: {len(results)}/{total_tasks}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"\\n请求失败 {url}: {e}\")\n",
        "                        results.append({\"error\": str(e), \"url\": url})\n",
        "                        pbar.update(1)\n",
        "        \n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"任务完成! 总耗时: {elapsed_time:.2f}秒\")\n",
        "        print(f\"平均每个请求: {elapsed_time/total_tasks:.2f}秒\")\n",
        "        \n",
        "        # 统计成功失败\n",
        "        success_count = sum(1 for r in results if 'error' not in r)\n",
        "        error_count = total_tasks - success_count\n",
        "        print(f\"成功: {success_count}, 失败: {error_count}\")\n",
        "        \n",
        "        return results\n",
        "    def parse_batch_fetch_all_with_progress_达人数据(self,f):\n",
        "        data_F=pd.DataFrame(data=f)\n",
        "        return data_F\n",
        "    \n",
        "\n",
        "    def get_达人数据(self,cookie_name):\n",
        "        data=[]\n",
        "        url=api_json[\"创作者中心_签约博主_达人数据\"]\n",
        "        session=requests.Session()\n",
        "        retry_strategy = Retry(\n",
        "                total=5,  # 总重试次数\n",
        "                backoff_factor=10,  # 退避因子\n",
        "                status_forcelist=[429, 500, 502, 503, 504],  # 需要重试的HTTP状态码\n",
        "                allowed_methods=[\"GET\"]  # 允许重试的方法\n",
        "            )\n",
        "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "        session.mount(\"http://\", adapter)\n",
        "        session.mount(\"https://\", adapter)\n",
        "\n",
        "        params = {\n",
        "            'keyword': '',\n",
        "            'pageNum': '1',\n",
        "            'pageSize': '100',\n",
        "        }\n",
        "        try:\n",
        "            total_page=session.get(url=url,cookies=cookie.czzzx_cookie_json[cookie_name],headers=cookie.czzzx_headers_json[cookie_name],timeout=30,verify=False).json()\n",
        "            total=total_page['data']['total']\n",
        "            total_pages=(total//100)+1\n",
        "            logger.info(f\"签约博主: {total}, 签约博主: {total_pages}\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logger.error(f\"请求失败，错误: {e}\")\n",
        "            return None\n",
        "        \n",
        "        for page in range(1,total_pages+1):\n",
        "            params['pageNum']=str(page)\n",
        "            try:\n",
        "                response = session.get(\n",
        "                    url=url,\n",
        "                    params=params,\n",
        "                    cookies=cookie.czzzx_cookie_json[cookie_name],\n",
        "                    headers=cookie.czzzx_headers_json[cookie_name],\n",
        "                    timeout=30,\n",
        "                    verify=False\n",
        "                    )\n",
        "                response.raise_for_status()  # 如果响应状态码不是200，抛出异常\n",
        "                logger.info(f\"请求成功，状态码: {response.status_code}, 页码: {page}\")\n",
        "                data.append(response.json()[\"data\"][\"kols\"])\n",
        "                    \n",
        "            except requests.exceptions.RequestException as e:\n",
        "                logger.error(f\"请求失败，错误: {e}, 页码: {page}\")\n",
        "                return None\n",
        "        data=list(chain.from_iterable(data))\n",
        "        names = list(map(lambda x: x['userName'], data))\n",
        "        userId = list(map(lambda x: x['userId'], data))\n",
        "        timelineTypes = list(map(lambda x: x['timelineTypes'], data))\n",
        "        fansNum = list(map(lambda x: x['fansNum'], data))\n",
        "        favLikeNum = list(map(lambda x: x['favLikeNum'], data))\n",
        "        noteNum = list(map(lambda x: x['noteNum'], data))\n",
        "        tags = list(map(lambda x: x['tags'], data))\n",
        "        \n",
        "        data=pd.DataFrame({'用户昵称':names,'用户ID':userId,\"账号标签\":tags,'timelineTypes':timelineTypes,'获赞与收藏':favLikeNum,'粉丝数':fansNum,'笔记数':noteNum,\"来源\":cookie_name})\n",
        "        data[\"抓取时间\"]=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        data[\"账号标签\"]=data[\"账号标签\"].apply(lambda x:str(x).replace(\"[\",\"\"))\n",
        "        data[\"账号标签\"]=data[\"账号标签\"].apply(lambda x:str(x).replace(\"]\",\"\"))\n",
        "        return data\n",
        "    def get_热门话题(self,cookie_name):\n",
        "        data=[]\n",
        "        url=api_json[\"创作者中心_热门话题\"]\n",
        "        session=requests.Session()\n",
        "        retry_strategy = Retry(\n",
        "                total=5,  # 总重试次数\n",
        "                backoff_factor=10,  # 退避因子\n",
        "                status_forcelist=[429, 500, 502, 503, 504],  # 需要重试的HTTP状态码\n",
        "                allowed_methods=[\"GET\"]  # 允许重试的方法\n",
        "            )\n",
        "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "        session.mount(\"http://\", adapter)\n",
        "        session.mount(\"https://\", adapter)\n",
        "\n",
        "        try:\n",
        "            response=session.get(url=url,cookies=cookie.czzzx_cookie_json[cookie_name],headers=cookie.czzzx_headers_json[cookie_name],timeout=30,verify=False)\n",
        "            response_data=response.json()[\"data\"]\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logger.error(f\"请求失败，错误: {e}\")\n",
        "            return None\n",
        "        \n",
        "        \n",
        "        for i in range(len(response_data)):\n",
        "            labelName=response_data[i][\"labelName\"]\n",
        "            for j in range(len(response_data[i][\"selectTopics\"])):\n",
        "                fz=response_data[i]['selectTopics'][j][\"notes\"]\n",
        "                joinNum=response_data[i]['selectTopics'][j][\"joinNum\"]\n",
        "                pageId=response_data[i]['selectTopics'][j][\"pageId\"]\n",
        "                subject_2=response_data[i]['selectTopics'][j][\"title\"]\n",
        "                viewNum=response_data[i]['selectTopics'][j][\"viewNum\"]\n",
        "                for m in range(len(fz)):\n",
        "                    noteId=fz[m][\"noteId\"]\n",
        "                    note_title=fz[m][\"title\"]\n",
        "                    note_type=fz[m][\"type\"]\n",
        "                    note_likes=fz[m][\"likes\"]\n",
        "                    data.append([labelName,subject_2,joinNum,pageId,viewNum,noteId,note_title,note_type,note_likes])\n",
        "        data_F=pd.DataFrame(data,columns=[\"一级标题\",'二级标题','参与量','PageID','浏览量',\"笔记ID\",'笔记标题','笔记类型','笔记点赞数'])\n",
        "        data_F[\"来源\"]=cookie_name\n",
        "        \n",
        "        data_F[\"视频URL\"]='https://www.xiaohongshu.com/explore/'+data_F[\"笔记ID\"]+\\\n",
        "        \"?app_platform=android&ignoreEngage=true&app_version=9.19.0&share_from_user_hidden=true&xsec_source=app_share&type=\"+data_F[\"笔记类型\"]\n",
        "        \n",
        "        data_F[\"笔记类型\"]=data_F[\"笔记类型\"].map({\"video\":\"视频\",'normal':\"图文\"})\n",
        "        data_F[\"抓取时间\"]=datetime.now().strftime( \"%Y-%m-%d %H:%M:%S\")\n",
        "        return data_F\n",
        "\n",
        "\n",
        "\n",
        "    def fetch_single(self,url,cookie_name):\n",
        "        try:\n",
        "            proxy_one=proxy_pool.get_proxy()\n",
        "            response = requests.get(url, timeout=60,proxies=proxy_one,cookies=cookie.czzzx_cookie_json[cookie_name],headers=cookie.czzzx_headers_json[cookie_name])\n",
        "            print(proxy_one)\n",
        "            return response.json()\n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e)}\n",
        "    def batch_fetch_all_with_progress(self,cookie_name,base_url_list, max_workers):\n",
        "        \"\"\"批量并发请求\"\"\"\n",
        "        results = []\n",
        "        total_tasks = len(base_url_list)\n",
        "        \n",
        "        print(f\"开始批量请求，共 {total_tasks} 个任务，并发数: {max_workers}\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "            # 提交所有任务\n",
        "            future_to_url = {executor.submit(self.fetch_single, url, cookie_name): url for url in base_url_list}\n",
        "            \n",
        "            # 使用tqdm显示进度\n",
        "            with tqdm(total=total_tasks, desc=\"处理进度\", unit=\"个\", ncols=100) as pbar:\n",
        "                # 按完成顺序获取结果\n",
        "                for future in as_completed(future_to_url):\n",
        "                    url = future_to_url[future]\n",
        "                    try:\n",
        "                        result = future.result()\n",
        "                        results.append(result)\n",
        "                        pbar.update(1)  # 更新进度条\n",
        "                        pbar.set_postfix_str(f\"已处理: {len(results)}/{total_tasks}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"\\n请求失败 {url}: {e}\")\n",
        "                        results.append({\"error\": str(e), \"url\": url})\n",
        "                        pbar.update(1)\n",
        "        \n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"任务完成! 总耗时: {elapsed_time:.2f}秒\")\n",
        "        print(f\"平均每个请求: {elapsed_time/total_tasks:.2f}秒\")\n",
        "        \n",
        "        # 统计成功失败\n",
        "        success_count = sum(1 for r in results if 'error' not in r)\n",
        "        error_count = total_tasks - success_count\n",
        "        print(f\"成功: {success_count}, 失败: {error_count}\")\n",
        "        \n",
        "        return results\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a01c58",
      "metadata": {},
      "source": [
        "# get_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "88e540f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "class czzzx_Main:\n",
        "    def __init__(self):\n",
        "        self.cookie_name=[i for i in cookie.czzzx_cookie_json.keys()]\n",
        "        self.czzzx_data=czzzx_method_Set()\n",
        "    def get_data(self,cookie_name):\n",
        "        # 合作中\n",
        "        self.data_合作中=self.czzzx_data.data_创作者中心_签约关系列表_合作中(cookie_name)\n",
        "        # 已终止\n",
        "        self.data_已终止=self.czzzx_data.data_创作者中心_签约关系列表_已终止(cookie_name)\n",
        "        # 签约邀请\n",
        "        self.data_签约邀请=self.czzzx_data.data_创作者中心_签约邀请(cookie_name=cookie_name,applyType=\"1,2,4,5\")\n",
        "        # 解约列表\n",
        "        self.data_解约列表=self.czzzx_data.data_创作者中心_签约邀请(cookie_name=cookie_name,applyType=\"3\")\n",
        "        # 机构总览\n",
        "        self.data_机构总览=self.czzzx_data.get_创作者中心_机构总览(cookie_name)\n",
        "        # 机构总览_数据概览\n",
        "        self.data_机构总览_数据概览=self.czzzx_data.get_创作者中心_机构总览_数据概览(cookie_name)\n",
        "        # 涨粉能力排名\n",
        "        self.data_涨粉能力排名=self.czzzx_data.get_创作者中心_博主排名_涨粉能力排名(cookie_name)\n",
        "        #博主合作排名\n",
        "        self.data_博主合作排名=self.czzzx_data.get_创作者中心_博主排名_博主合作排名(cookie_name)\n",
        "        # 买手合作排名\n",
        "        self.data_买手合作排名=self.czzzx_data.get_创作者中心_博主排名_买手合作排名(cookie_name)\n",
        "        # 笔记播放or阅读排名\n",
        "        self.data_笔记播放or阅读排名=self.czzzx_data.get_创作者中心_笔记排名_笔记播放or阅读排名(cookie_name)\n",
        "        # 笔记涨粉能力排名\n",
        "        self.data_笔记涨粉能力排名=self.czzzx_data.get_创作者中心_笔记排名_笔记涨粉能力排名(cookie_name)\n",
        "        # 达人数据\n",
        "        params_list=[{\"userId\":i} for i in self.data_合作中[\"用户ID\"]]\n",
        "        f=self.czzzx_data.batch_fetch_all_with_progress_达人数据(cookie_name=cookie_name,params=params_list,max_workers=50,times=30,proxy=0)\n",
        "        self.data_达人数据=self.czzzx_data.parse_batch_fetch_all_with_progress_达人数据(f)\n",
        "\n",
        "\n",
        "        # 达人数据  带账号标签\n",
        "        self.达人数据Pro=self.czzzx_data.get_达人数据(cookie_name)\n",
        "        # self.data_达人数据Pro=pd.merge(left=self.data_达人数据,right=self.达人数据Pro,how=\"inner\",left_on=\"用户ID\",right_on=\"用户ID\")\n",
        "        # 话题数据\n",
        "        self.data_话题数据=self.czzzx_data.get_热门话题(cookie_name)\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b585743",
      "metadata": {},
      "source": [
        "# 插入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fe7fd7af",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:数据已成功插入到表 话题数据 中，共 391 条记录。\n",
            "INFO:__main__:全部表插入成功，事务已提交\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "派芽生活 --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约关系列表_合作中: 2086, 签约关系列表_合作中: 21\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 11\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 12\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 13\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 14\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 15\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 16\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 17\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 18\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 19\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 20\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 21\n",
            "INFO:__main__:派芽生活 创作者中心_签约关系列表 数据获取完成,共 21 条数据\n",
            "INFO:__main__:签约关系列表_已终止合作: 1146, 签约关系列表_已终止合作: 12\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 11\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 12\n",
            "INFO:__main__:派芽生活 创作者中心_签约关系列表 数据获取完成,共 12 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 4921, 创作者中心_签约邀请: 50\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 11\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 12\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 13\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 14\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 15\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 16\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 17\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 18\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 19\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 20\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 21\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 22\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 23\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 24\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 25\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 26\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 27\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 28\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 29\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 30\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 31\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 32\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 33\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 34\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 35\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 36\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 37\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 38\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 39\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 40\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 41\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 42\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 43\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 44\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 45\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 46\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 47\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 48\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 49\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 50\n",
            "INFO:__main__:派芽生活 data_创作者中心_签约邀请 数据获取完成,共 50 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 4921, 创作者中心_签约邀请: 50\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 11\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 12\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 13\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 14\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 15\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 16\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 17\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 18\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 19\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 20\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 21\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 22\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 23\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 24\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 25\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 26\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 27\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 28\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 29\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 30\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 31\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 32\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 33\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 34\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 35\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 36\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 37\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 38\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 39\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 40\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 41\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 42\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 43\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 44\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 45\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 46\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 47\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 48\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 49\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 50\n",
            "INFO:__main__:派芽生活 data_创作者中心_签约邀请 数据获取完成,共 50 条数据\n",
            "WARNING:__main__:GET失败 第1/5次: https://creator.xiaohongshu.com/api/galaxy/mcn/data/user_statistics params={'time': '30'} err=接口返回success=false，msg=系统异常, code=-1, data=ce1691eb3cc30d40b63e57f80432cd39\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始批量请求，共 2086 个任务，并发数: 50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "处理进度: 100%|██████████████████████████████| 2086/2086 [02:46<00:00, 12.51个/s, 已处理: 2086/2086]/个]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "任务完成! 总耗时: 166.86秒\n",
            "平均每个请求: 0.08秒\n",
            "成功: 2086, 失败: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约博主: 2086, 签约博主: 21\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 11\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 12\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 13\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 14\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 15\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 16\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 17\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 18\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 19\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 20\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 21\n",
            "INFO:__main__:数据已成功插入到表 合作中达人 中，共 2086 条记录。\n",
            "INFO:__main__:数据已成功插入到表 已终止达人 中，共 1146 条记录。\n",
            "INFO:__main__:数据已成功插入到表 签约邀请 中，共 3802 条记录。\n",
            "INFO:__main__:数据已成功插入到表 解约列表 中，共 1119 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构数据概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_博主合作排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_买手合作排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记播放阅读排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据 中，共 2086 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据_Ctag 中，共 2086 条记录。\n",
            "INFO:__main__:全部表插入成功，事务已提交\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "派芽星球 --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约关系列表_合作中: 902, 签约关系列表_合作中: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:派芽星球 创作者中心_签约关系列表 数据获取完成,共 10 条数据\n",
            "INFO:__main__:签约关系列表_已终止合作: 438, 签约关系列表_已终止合作: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:派芽星球 创作者中心_签约关系列表 数据获取完成,共 5 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 1885, 创作者中心_签约邀请: 19\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 11\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 12\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 13\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 14\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 15\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 16\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 17\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 18\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 19\n",
            "INFO:__main__:派芽星球 data_创作者中心_签约邀请 数据获取完成,共 19 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 1885, 创作者中心_签约邀请: 19\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 11\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 12\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 13\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 14\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 15\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 16\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 17\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 18\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 19\n",
            "INFO:__main__:派芽星球 data_创作者中心_签约邀请 数据获取完成,共 19 条数据\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始批量请求，共 902 个任务，并发数: 50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "处理进度: 100%|██████████████████████████████████| 902/902 [01:24<00:00, 10.68个/s, 已处理: 902/902]/个]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "任务完成! 总耗时: 84.50秒\n",
            "平均每个请求: 0.09秒\n",
            "成功: 902, 失败: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约博主: 902, 签约博主: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:数据已成功插入到表 合作中达人 中，共 902 条记录。\n",
            "INFO:__main__:数据已成功插入到表 已终止达人 中，共 438 条记录。\n",
            "INFO:__main__:数据已成功插入到表 签约邀请 中，共 1462 条记录。\n",
            "INFO:__main__:数据已成功插入到表 解约列表 中，共 423 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构数据概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_博主合作排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_买手合作排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记播放阅读排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据 中，共 902 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据_Ctag 中，共 902 条记录。\n",
            "INFO:__main__:全部表插入成功，事务已提交\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "派芽母婴 --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约关系列表_合作中: 13, 签约关系列表_合作中: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:派芽母婴 创作者中心_签约关系列表 数据获取完成,共 1 条数据\n",
            "INFO:__main__:签约关系列表_已终止合作: 1, 签约关系列表_已终止合作: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:派芽母婴 创作者中心_签约关系列表 数据获取完成,共 1 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 19, 创作者中心_签约邀请: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:派芽母婴 data_创作者中心_签约邀请 数据获取完成,共 1 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 19, 创作者中心_签约邀请: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:派芽母婴 data_创作者中心_签约邀请 数据获取完成,共 1 条数据\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始批量请求，共 13 个任务，并发数: 50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "处理进度: 100%|██████████████████████████████████████| 13/13 [00:02<00:00,  4.51个/s, 已处理: 13/13]/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "任务完成! 总耗时: 2.90秒\n",
            "平均每个请求: 0.22秒\n",
            "成功: 13, 失败: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约博主: 13, 签约博主: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:数据已成功插入到表 合作中达人 中，共 13 条记录。\n",
            "INFO:__main__:数据已成功插入到表 已终止达人 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 签约邀请 中，共 17 条记录。\n",
            "INFO:__main__:数据已成功插入到表 解约列表 中，共 2 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构数据概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_涨粉能力排名 中，共 6 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_博主合作排名 中，共 6 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_买手合作排名 中，共 0 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记播放阅读排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据 中，共 13 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据_Ctag 中，共 13 条记录。\n",
            "INFO:__main__:全部表插入成功，事务已提交\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "派芽地球 --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约关系列表_合作中: 39, 签约关系列表_合作中: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:派芽地球 创作者中心_签约关系列表 数据获取完成,共 1 条数据\n",
            "INFO:__main__:签约关系列表_已终止合作: 3061, 签约关系列表_已终止合作: 31\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 11\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 12\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 13\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 14\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 15\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 16\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 17\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 18\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 19\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 20\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 21\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 22\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 23\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 24\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 25\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 26\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 27\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 28\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 29\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 30\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 31\n",
            "INFO:__main__:派芽地球 创作者中心_签约关系列表 数据获取完成,共 31 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 6551, 创作者中心_签约邀请: 66\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 11\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 12\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 13\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 14\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 15\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 16\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 17\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 18\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 19\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 20\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 21\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 22\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 23\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 24\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 25\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 26\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 27\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 28\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 29\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 30\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 31\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 32\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 33\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 34\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 35\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 36\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 37\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 38\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 39\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 40\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 41\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 42\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 43\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 44\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 45\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 46\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 47\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 48\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 49\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 50\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 51\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 52\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 53\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 54\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 55\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 56\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 57\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 58\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 59\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 60\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 61\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 62\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 63\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 64\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 65\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 66\n",
            "INFO:__main__:派芽地球 data_创作者中心_签约邀请 数据获取完成,共 66 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 6551, 创作者中心_签约邀请: 66\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 8\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 9\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 10\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 11\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 12\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 13\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 14\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 15\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 16\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 17\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 18\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 19\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 20\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 21\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 22\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 23\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 24\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 25\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 26\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 27\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 28\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 29\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 30\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 31\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 32\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 33\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 34\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 35\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 36\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 37\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 38\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 39\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 40\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 41\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 42\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 43\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 44\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 45\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 46\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 47\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 48\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 49\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 50\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 51\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 52\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 53\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 54\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 55\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 56\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 57\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 58\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 59\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 60\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 61\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 62\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 63\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 64\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 65\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 66\n",
            "INFO:__main__:派芽地球 data_创作者中心_签约邀请 数据获取完成,共 66 条数据\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始批量请求，共 39 个任务，并发数: 50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "处理进度: 100%|██████████████████████████████████████| 39/39 [00:05<00:00,  7.49个/s, 已处理: 39/39]/个]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "任务完成! 总耗时: 5.27秒\n",
            "平均每个请求: 0.14秒\n",
            "成功: 39, 失败: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约博主: 39, 签约博主: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:数据已成功插入到表 合作中达人 中，共 39 条记录。\n",
            "INFO:__main__:数据已成功插入到表 已终止达人 中，共 3061 条记录。\n",
            "INFO:__main__:数据已成功插入到表 签约邀请 中，共 4703 条记录。\n",
            "INFO:__main__:数据已成功插入到表 解约列表 中，共 1848 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构数据概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_博主合作排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_买手合作排名 中，共 3 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记播放阅读排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据 中，共 39 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据_Ctag 中，共 39 条记录。\n",
            "INFO:__main__:全部表插入成功，事务已提交\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "派芽月球 --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约关系列表_合作中: 63, 签约关系列表_合作中: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:派芽月球 创作者中心_签约关系列表 数据获取完成,共 1 条数据\n",
            "INFO:__main__:签约关系列表_已终止合作: 290, 签约关系列表_已终止合作: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:派芽月球 创作者中心_签约关系列表 数据获取完成,共 3 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 622, 创作者中心_签约邀请: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:派芽月球 data_创作者中心_签约邀请 数据获取完成,共 7 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 622, 创作者中心_签约邀请: 7\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 3\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 4\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 5\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 6\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 7\n",
            "INFO:__main__:派芽月球 data_创作者中心_签约邀请 数据获取完成,共 7 条数据\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始批量请求，共 63 个任务，并发数: 50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "处理进度: 100%|██████████████████████████████████████| 63/63 [00:02<00:00, 26.05个/s, 已处理: 63/63]/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "任务完成! 总耗时: 6.24秒\n",
            "平均每个请求: 0.10秒\n",
            "成功: 63, 失败: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约博主: 63, 签约博主: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:数据已成功插入到表 合作中达人 中，共 63 条记录。\n",
            "INFO:__main__:数据已成功插入到表 已终止达人 中，共 290 条记录。\n",
            "INFO:__main__:数据已成功插入到表 签约邀请 中，共 448 条记录。\n",
            "INFO:__main__:数据已成功插入到表 解约列表 中，共 174 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构数据概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_博主合作排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_买手合作排名 中，共 0 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记播放阅读排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据 中，共 63 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据_Ctag 中，共 63 条记录。\n",
            "INFO:__main__:全部表插入成功，事务已提交\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "派芽家居 --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约关系列表_合作中: 3, 签约关系列表_合作中: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:派芽家居 创作者中心_签约关系列表 数据获取完成,共 1 条数据\n",
            "INFO:__main__:签约关系列表_已终止合作: 0, 签约关系列表_已终止合作: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:派芽家居 创作者中心_签约关系列表 数据获取完成,共 1 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 3, 创作者中心_签约邀请: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:派芽家居 data_创作者中心_签约邀请 数据获取完成,共 1 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 3, 创作者中心_签约邀请: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:派芽家居 data_创作者中心_签约邀请 数据获取完成,共 1 条数据\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始批量请求，共 3 个任务，并发数: 50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "处理进度: 100%|██████████████████████████████████████████| 3/3 [00:00<00:00,  4.67个/s, 已处理: 3/3]/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "任务完成! 总耗时: 0.65秒\n",
            "平均每个请求: 0.22秒\n",
            "成功: 3, 失败: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约博主: 3, 签约博主: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:数据已成功插入到表 合作中达人 中，共 3 条记录。\n",
            "INFO:__main__:数据已成功插入到表 已终止达人 中，共 0 条记录。\n",
            "INFO:__main__:数据已成功插入到表 签约邀请 中，共 3 条记录。\n",
            "INFO:__main__:数据已成功插入到表 解约列表 中，共 0 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构数据概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_涨粉能力排名 中，共 3 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_博主合作排名 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_买手合作排名 中，共 0 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记播放阅读排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据 中，共 3 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据_Ctag 中，共 3 条记录。\n",
            "INFO:__main__:全部表插入成功，事务已提交\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "派芽美护 --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约关系列表_合作中: 156, 签约关系列表_合作中: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:派芽美护 创作者中心_签约关系列表 数据获取完成,共 2 条数据\n",
            "INFO:__main__:签约关系列表_已终止合作: 16, 签约关系列表_已终止合作: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:派芽美护 创作者中心_签约关系列表 数据获取完成,共 1 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 199, 创作者中心_签约邀请: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:派芽美护 data_创作者中心_签约邀请 数据获取完成,共 2 条数据\n",
            "INFO:__main__:创作者中心_签约邀请: 199, 创作者中心_签约邀请: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:派芽美护 data_创作者中心_签约邀请 数据获取完成,共 2 条数据\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始批量请求，共 156 个任务，并发数: 50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "处理进度: 100%|██████████████████████████████████| 156/156 [00:10<00:00, 14.28个/s, 已处理: 156/156]/个]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "任务完成! 总耗时: 11.31秒\n",
            "平均每个请求: 0.07秒\n",
            "成功: 156, 失败: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:__main__:签约博主: 156, 签约博主: 2\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 1\n",
            "INFO:__main__:请求成功，状态码: 200, 页码: 2\n",
            "INFO:__main__:数据已成功插入到表 合作中达人 中，共 156 条记录。\n",
            "INFO:__main__:数据已成功插入到表 已终止达人 中，共 16 条记录。\n",
            "INFO:__main__:数据已成功插入到表 签约邀请 中，共 176 条记录。\n",
            "INFO:__main__:数据已成功插入到表 解约列表 中，共 23 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 机构数据概览 中，共 1 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_博主合作排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 博主排名_买手合作排名 中，共 3 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记播放阅读排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 笔记排名_笔记涨粉能力排名 中，共 10 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据 中，共 156 条记录。\n",
            "INFO:__main__:数据已成功插入到表 达人数据_Ctag 中，共 156 条记录。\n",
            "INFO:__main__:全部表插入成功，事务已提交\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cookie_list=[i for i in cookie.czzzx_cookie_json.keys()]\n",
        "czzzx=czzzx_Main()\n",
        "\n",
        "try:\n",
        "     with engine.begin() as conn2:\n",
        "    # 话题数据,运行一次即可，无需每个主题都运行\n",
        "        xls_to_sql(\"话题数据\",czzzx_method_Set().get_热门话题(\"派芽生活\"), confirm=True, conn=conn2)\n",
        "        logger.info(\"全部表插入成功，事务已提交\")\n",
        "except SQLAlchemyError as e:\n",
        "    logger.error(f\"插入过程中出错，所有插入已回滚: {e}\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    logger.error(f\"发生未预期的错误，所有插入已回滚: {e}\")\n",
        "    raise\n",
        "\n",
        "for i in cookie_list:\n",
        "    print(i,\"-\"*200)\n",
        "    czzzx.get_data(i)\n",
        "    try:\n",
        "        # 使用同一个事务批量插入，任意一张表失败则全部回滚\n",
        "        with engine.begin() as conn:\n",
        "            # 合作中达人\n",
        "            xls_to_sql(\"合作中达人\", czzzx.data_合作中, confirm=True, conn=conn)\n",
        "\n",
        "            # 已终止达人\n",
        "            xls_to_sql(\"已终止达人\", czzzx.data_已终止, confirm=True, conn=conn)\n",
        "\n",
        "            # 签约邀请\n",
        "            xls_to_sql(\"签约邀请\", czzzx.data_签约邀请, confirm=True, conn=conn)\n",
        "\n",
        "            # 解约列表\n",
        "            xls_to_sql(\"解约列表\", czzzx.data_解约列表, confirm=True, conn=conn)\n",
        "\n",
        "            # 机构概览\n",
        "            xls_to_sql(\"机构概览\", czzzx.data_机构总览, confirm=True, conn=conn)\n",
        "\n",
        "            # 机构概览_数据概览\n",
        "            xls_to_sql(\"机构数据概览\", czzzx.data_机构总览_数据概览, confirm=True, conn=conn)\n",
        "\n",
        "            # 涨粉能力排名\n",
        "            xls_to_sql(\"博主排名_涨粉能力排名\", czzzx.data_涨粉能力排名, confirm=True, conn=conn)\n",
        "\n",
        "            # 博主合作排名\n",
        "            xls_to_sql(\"博主排名_博主合作排名\", czzzx.data_博主合作排名, confirm=True, conn=conn)\n",
        "\n",
        "            # 买手合作排名\n",
        "            xls_to_sql(\"博主排名_买手合作排名\", czzzx.data_买手合作排名, confirm=True, conn=conn)\n",
        "\n",
        "            # 笔记播放/阅读排名\n",
        "            xls_to_sql(\"笔记排名_笔记播放阅读排名\", czzzx.data_笔记播放or阅读排名, confirm=True, conn=conn)\n",
        "\n",
        "            # 笔记涨粉能力排名\n",
        "            xls_to_sql(\"笔记排名_笔记涨粉能力排名\", czzzx.data_笔记涨粉能力排名, confirm=True, conn=conn)\n",
        "\n",
        "            # 达人数据（明细）\n",
        "            xls_to_sql(\"达人数据\", czzzx.data_达人数据, confirm=True, conn=conn)\n",
        "\n",
        "            # 达人数据（带账号标签）\n",
        "            xls_to_sql(\"达人数据_Ctag\", czzzx.达人数据Pro, confirm=True, conn=conn)\n",
        "        logger.info(\"全部表插入成功，事务已提交\")\n",
        "    except SQLAlchemyError as e:\n",
        "        logger.error(f\"插入过程中出错，所有插入已回滚: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logger.error(f\"发生未预期的错误，所有插入已回滚: {e}\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da0772ef",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efe6b3fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90be1ecb",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "45129991",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f25a185",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76c50c59",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5736b5",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "831c6f0f-e280-4dd8-a55d-64096221fdeb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_蒲公英_签约博主(url,cookie,headers,name):\n",
        "    params = {\n",
        "        'keyword': name,\n",
        "        'column': '',\n",
        "        'sort': '',\n",
        "        'pageNum': '1',\n",
        "        'pageSize': '20',\n",
        "        'kolType': '0',\n",
        "    }\n",
        "\n",
        "    response = requests.get(\n",
        "        url=url,\n",
        "        params=params,\n",
        "        cookies=cookie,\n",
        "        headers=headers,\n",
        "        verify=False\n",
        "    )\n",
        "    return response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "83f7f1b8-54a8-4a6d-9649-3c6841d63342",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'蒲公英_签约博主'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m get_蒲公英_签约博主(url=\u001b[43mapi_json\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m蒲公英_签约博主\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m,cookie=cookie.pgy_cookie_json[\u001b[33m\"\u001b[39m\u001b[33m派芽生活\u001b[39m\u001b[33m\"\u001b[39m],headers=cookie.pgy_headers_json[\u001b[33m\"\u001b[39m\u001b[33m派芽生活\u001b[39m\u001b[33m\"\u001b[39m],name=\u001b[33m\"\u001b[39m\u001b[33m派芽生活\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mKeyError\u001b[39m: '蒲公英_签约博主'"
          ]
        }
      ],
      "source": [
        "get_蒲公英_签约博主(url=api_json['蒲公英_签约博主'],cookie=cookie.pgy_cookie_json[\"派芽生活\"],headers=cookie.pgy_headers_json[\"派芽生活\"],name=\"派芽生活\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "113514c9-4b85-4d2b-ba88-e34012db2d7f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c391aa15-ed82-4a1b-a8a0-966ced6522fe",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0ab201a-5b9d-45f4-a9d7-52c4113cb337",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
